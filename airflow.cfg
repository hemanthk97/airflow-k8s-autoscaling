[core]
airflow_home = /etc/airflow
dags_folder = /home/airflow/gcs/dags
base_log_folder = /home/airflow/gcs/logs
plugins_folder = /home/airflow/gcs/plugins
remote_logging = True
remote_log_conn_id = google_cloud_default
remote_base_log_folder = gs://asia-northeast1-mem-airflow-5be0ca51-bucket/logs
executor = CeleryExecutor
dags_are_paused_at_creation = False
load_examples = False
donot_pickle = True
dagbag_import_timeout = 30
fernet_key = MuKpn55qS7uY_xpaBfJhpKRME2fQ-4MZwIziXB938aw=
parallelism = 200
dag_concurrency = 100
max_active_runs_per_dag = 100
enable_xcom_pickling = False
sql_alchemy_pool_recycle = 1800

[webserver]
web_server_host = 0.0.0.0
web_server_port = 8080
secret_key = temporary_key
workers = 2
worker_class = sync
expose_config = True
web_server_name = mem-airflow
async_dagbag_loader = False
worker_refresh_interval = 60
web_server_worker_timeout = 60

[celery]
celery_app_name = airflow.executors.celery_executor
worker_concurrency = 100
worker_log_server_port = 8793
broker_url = redis://airflow-redis-service.default.svc.cluster.local:6379/0
result_backend = redis://airflow-redis-service.default.svc.cluster.local:6379/0
flower_port = 5555
default_queue = default
ssl_active = False

[email]
email_backend = airflow.contrib.utils.sendgrid.send_email

[smtp]
smtp_host = localhost
smtp_starttls = True
smtp_ssl = False
smtp_user = airflow
smtp_port = 25
smtp_password = airflow
smtp_mail_from = no-reply@cloud.google.com

[scheduler]
dag_dir_list_interval = 100
statsd_on = True
statsd_host = airflow-monitoring-service.default.svc.cluster.local
statsd_port = 8125
statsd_prefix = airflow

[kubernetes]
in_cluster = True
